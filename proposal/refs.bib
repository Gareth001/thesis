@article{MIMICIIIdatabase,
issn = {20524463},
journal = {Scientific Data},
volume = {3},
publisher = {Nature Publishing Group},
number = {1},
year = {2016},
title = {MIMIC-III, a freely accessible critical care database},
author = {Alistair E.W. Johnson and Tom J. Pollard and Lu Shen and Li-Wei H. Lehman and Mengling Feng and Mohammad Ghassemi and Benjamin Moody and Peter Szolovits and Leo Anthony Celi and Roger G. Mark},
keywords = {Critical Care ; Databases, Factual;},
}


@Article{DermLevel2017,
author={Esteva, Andre
and Kuprel, Brett
and Novoa, Roberto A.
and Ko, Justin
and Swetter, Susan M.
and Blau, Helen M.
and Thrun, Sebastian},
title={Dermatologist-level classification of skin cancer with deep neural networks},
journal={Nature},
year={2017},
month={Jan},
day={25},
publisher={Macmillan Publishers Limited, part of Springer Nature. All rights reserved. SN  -},
volume={542},
pages={115 EP  -},
url={https://doi.org/10.1038/nature21056}
}

@article{KajiLSTM,
issn = {1932-6203},
abstract = {This study trained long short-term memory (LSTM) recurrent neural networks (RNNs) incorporating an attention mechanism to predict daily sepsis, myocardial infarction (MI), and vancomycin antibiotic administration over two week patient ICU courses in the MIMIC-III dataset. These models achieved next-day predictive AUC of 0.876 for sepsis, 0.823 for MI, and 0.833 for vancomycin administration. Attention maps built from these models highlighted those times when input variables most influenced predictions and could provide a degree of interpretability to clinicians. These models appeared to attend to variables that were proxies for clinician decision-making, demonstrating a challenge of using flexible deep learning approaches trained with EHR data to build clinical decision support. While continued development and refinement is needed, we believe that such models could one day prove useful in reducing information overload for ICU physicians by providing needed clinical decision support for a variety of clinically important tasks.},
journal = {PLoS ONE},
pages = {e0211057},
volume = {14},
publisher = {Public Library of Science},
number = {2},
year = {2019},
title = {An attention based deep learning model of clinical events in the intensive care unit.(Research Article)(Report)},
language = {English},
author = {Kaji, Deepak A. and Zech, John R. and Kim, Jun S. and Cho, Samuel K. and Dangayach, Neha S. and Costa, Anthony B. and Oermann, Eric K.},
keywords = {Antibacterial Agents -- Usage ; Heart Attack -- Risk Factors ; Decision Making -- Analysis ; Artificial Neural Networks -- Health Aspects},
}

@article{ICUgeneralize,
abstract = {A large volume of research has considered the creation of predictive models for clinical data; however, much existing literature reports results using only a single source of data. In this work, we evaluate the performance of models trained on the publicly-available eICU Collaborative Research Database. We show that cross-validation using many distinct centers provides a reasonable estimate of model performance in new centers. We further show that a single model trained across centers transfers well to distinct hospitals, even compared to a model retrained using hospital-specific data. Our results motivate the use of multi-center datasets for model development and highlight the need for data sharing among hospitals to maximize model performance.},
journal = {arXiv.org},
publisher = {Cornell University Library, arXiv.org},
year = {2018},
title = {Generalizability of predictive models for intensive care unit patients},
language = {eng},
address = {Ithaca},
author = {Johnson, Alistair and Pollard, Tom and Naumann, Tristan},
keywords = {Mathematical Models ; Performance Evaluation ; Hospitals ; Data Retrieval},
url = {http://search.proquest.com/docview/2151577087/},
}

@article{YoungKyle2019Dnno,
issn = {03029743},
abstract = {Deep learning techniques have proven high accuracy for identifying melanoma in digitised dermoscopic images. A strength is that these methods are not constrained by features that are pre-defined by human semantics. A down-side is that it is difficult to understand the rationale of the model predictions and to identify potential failure modes. This is a major barrier to adoption of deep learning in clinical practice. In this paper we ask if two existing local interpretability methods, Grad-CAM and Kernel SHAP, can shed light on convolutional neural networks trained in the context of melanoma detection. Our contributions are (i) we first explore the domain space via a reproducible, end-to-end learning framework that creates a suite of 30 models, all trained on a publicly available data set (HAM10000), (ii) we next explore the reliability of GradCAM and Kernel SHAP in this context via some basic sanity check experiments (iii) finally, we investigate a random selection of models from our suite...},
journal = {arXiv.org},
volume = {11797},
publisher = {Cornell University Library, arXiv.org},
isbn = {9783030338497},
year = {2019},
title = {Deep neural network or dermatologist?},
language = {eng},
address = {Ithaca},
author = {Young, Kyle and Booth, Gareth and Simpson, Becks and Dutton, Reuben and Shrapnel, Sally},
keywords = {Measurement Methods ; Model Accuracy ; Accuracy ; Semantics ; Deep Learning ; Failure Modes ; Artificial Neural Networks ; Neural Networks ; Skin Cancer ; Diagnostic Systems ; Kernels ; Melanoma ; Machine Learning ; Digitization ; Machine Learning ; Image and Video Processing},
url = {http://search.proquest.com/docview/2276715881/},
}

@Article{ColahLSTM,
author={Olah, C},
title={Understanding LSTM Networks},
year={2015},
month={Aug},
day={27},
url={https://colah.github.io/posts/2015-08-Understanding-LSTMs/}
}

@Article{RNNEffectiveness,
author={Karpathy, Andrej},
title={The Unreasonable Effectiveness of Recurrent Neural Networks},
year={2015},
month={May},
day={21},
url={http://karpathy.github.io/2015/05/21/rnn-effectiveness/}
}

@article{weng2018attention,
  title   = "Attention? Attention!",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io/lil-log",
  year    = "2018",
  url     = "http://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html"
}

@inproceedings{seq2seq,
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {3104--3112},
volume = {4},
publisher = {Neural information processing systems foundation},
number = {January},
year = {2014},
title = {Sequence to sequence learning with neural networks},
copyright = {Copyright 2015 Elsevier B.V., All rights reserved.},
author = {Sutskever, I. and Vinyals, O. and Le, Q.V.},
}

@article{AttentionPaper,
abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based...},
journal = {arXiv.org},
publisher = {Cornell University Library, arXiv.org},
year = {2016},
title = {Neural Machine Translation by Jointly Learning to Align and Translate},
language = {eng},
address = {Ithaca},
author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
keywords = {Machine Translation ; English Language ; Translations ; Qualitative Analysis ; Encoders-Decoders ; Machine Translation ; Neural Networks ; Computation and Language ; Machine Learning ; Neural and Evolutionary Computation ; Machine Learning},
url = {http://search.proquest.com/docview/2079082715/},
}


@Article{ICUFancyLSTM,
author={Thorsen-Meyer, Hans-Christian
and Nielsen, Annelaura B.
and Nielsen, Anna P.
and Kaas-Hansen, Benjamin Skov
and Toft, Palle
and Schierbeck, Jens
and Str{\o}m, Thomas
and Chmura, Piotr J.
and Heimann, Marc
and Dybdahl, Lars
and Spangsege, Lasse
and Hulsen, Patrick
and Belling, Kirstine
and Brunak, S{\o}ren
and Perner, Anders},
title={Dynamic and explainable machine learning prediction of mortality in patients in the intensive care unit: a retrospective study of high-frequency data in electronic patient records},
journal={The Lancet Digital Health},
year={2020},
month={Apr},
day={01},
publisher={Elsevier},
volume={2},
number={4},
pages={e179-e191},
abstract={BackgroundMany mortality prediction models have been developed for patients in intensive care units (ICUs); most are based on data available at ICU admission. We investigated whether machine learning methods using analyses of time-series data improved mortality prognostication for patients in the ICU by providing real-time predictions of 90-day mortality. In addition, we examined to what extent such a dynamic model could be made interpretable by quantifying and visualising the features that drive the predictions at different timepoints.},
issn={2589-7500},
doi={10.1016/S2589-7500(20)30018-2},
url={https://doi.org/10.1016/S2589-7500(20)30018-2}
}

@misc{keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}
@article{GRUODE,
abstract = {Modeling real-world multidimensional time series can be particularly challenging when these are sporadically observed (i.e., sampling is irregular both in time and across dimensions)-such as in the case of clinical patient data. To address these challenges, we propose (1) a continuous-time version of the Gated Recurrent Unit, building upon the recent Neural Ordinary Differential Equations (Chen et al., 2018), and (2) a Bayesian update network that processes the sporadic observations. We bring these two ideas together in our GRU-ODE-Bayes method. We then demonstrate that the proposed method encodes a continuity prior for the latent process and that it can exactly represent the Fokker-Planck dynamics of complex processes driven by a multidimensional stochastic differential equation. Additionally, empirical evaluation shows that our method outperforms the state of the art on both synthetic data and real-world data with applications in healthcare and climate forecast. What is more, the continuity...},
journal = {arXiv.org},
publisher = {Cornell University Library, arXiv.org},
year = {2019},
title = {GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series},
language = {eng},
address = {Ithaca},
author = {De Brouwer, Edward and Simm, Jaak and Arany, Adam and Moreau, Yves},
keywords = {Mathematical Models ; Differential Equations ; Bayesian Analysis ; Time Series ; Modelling ; Ordinary Differential Equations ; Time Series ; Empirical Equations ; Machine Learning},
url = {http://search.proquest.com/docview/2232265113/},
}

@article {MIMIC_BMJ_RF,
	author = {McWilliams, Christopher J and Lawson, Daniel J and Santos-Rodriguez, Raul and Gilchrist, Iain D and Champneys, Alan and Gould, Timothy H and Thomas, Mathew JC and Bourdeaux, Christopher P},
	title = {Towards a decision support tool for intensive care discharge: machine learning algorithm development using electronic healthcare data from MIMIC-III and Bristol, UK},
	volume = {9},
	number = {3},
	elocation-id = {e025925},
	year = {2019},
	doi = {10.1136/bmjopen-2018-025925},
	publisher = {British Medical Journal Publishing Group},
	abstract = {Objective The primary objective is to develop an automated method for detecting patients that are ready for discharge from intensive care.Design We used two datasets of routinely collected patient data to test and improve on a set of previously proposed discharge criteria.Setting Bristol Royal Infirmary general intensive care unit (GICU).Patients Two cohorts derived from historical datasets: 1870 intensive care patients from GICU in Bristol, and 7592 from Medical Information Mart for Intensive Care (MIMIC)-III.Results In both cohorts few successfully discharged patients met all of the discharge criteria. Both a random forest and a logistic classifier, trained using multiple-source cross-validation, demonstrated improved performance over the original criteria and generalised well between the cohorts. The classifiers showed good agreement on which features were most predictive of readiness-for-discharge, and these were generally consistent with clinical experience. By weighting the discharge criteria according to feature importance from the logistic model we showed improved performance over the original criteria, while retaining good interpretability.Conclusions Our findings indicate the feasibility of the proposed approach to ready-for-discharge classification, which could complement other risk models of specific adverse outcomes in a future decision support system. Avenues for improvement to produce a clinically useful tool are identified.},
	issn = {2044-6055},
	URL = {https://bmjopen.bmj.com/content/9/3/e025925},
	eprint = {https://bmjopen.bmj.com/content/9/3/e025925.full.pdf},
	journal = {BMJ Open}
}

@article{CompareFourML,
author = {Hsieh, Meng and Hsieh, Meng and Chen, Chin-Ming and Hsieh, Chia-Chang and Chao, Chien-Ming and Lai, Chih-Cheng},
year = {2018},
month = {12},
pages = {},
title = {Comparison of machine learning models for the prediction of mortality of patients with unplanned extubation in intensive care units},
volume = {8},
journal = {Scientific Reports},
doi = {10.1038/s41598-018-35582-2}
}

@article{CoronaARDS,
    author = {Wu, Chaomin and Chen, Xiaoyan and Cai, Yanping and Xia, Jia’an and Zhou, Xing and Xu, Sha and Huang, Hanping and Zhang, Li and Zhou, Xia and Du, Chunling and Zhang, Yuye and Song, Juan and Wang, Sijiao and Chao, Yencheng and Yang, Zeyong and Xu, Jie and Zhou, Xin and Chen, Dechang and Xiong, Weining and Xu, Lei and Zhou, Feng and Jiang, Jinjun and Bai, Chunxue and Zheng, Junhua and Song, Yuanlin},
    title = "{Risk Factors Associated With Acute Respiratory Distress Syndrome and Death in Patients With Coronavirus Disease 2019 Pneumonia in Wuhan, China}",
    journal = {JAMA Internal Medicine},
    year = {2020},
    month = {03},
    abstract = "{Coronavirus disease 2019 (COVID-19) is an emerging infectious disease that was first reported in Wuhan, China, and has subsequently spread worldwide. Risk factors for the clinical outcomes of COVID-19 pneumonia have not yet been well delineated.To describe the clinical characteristics and outcomes in patients with COVID-19 pneumonia who developed acute respiratory distress syndrome (ARDS) or died.Retrospective cohort study of 201 patients with confirmed COVID-19 pneumonia admitted to Wuhan Jinyintan Hospital in China between December 25, 2019, and January 26, 2020. The final date of follow-up was February 13, 2020.Confirmed COVID-19 pneumonia.The development of ARDS and death. Epidemiological, demographic, clinical, laboratory, management, treatment, and outcome data were also collected and analyzed.Of 201 patients, the median age was 51 years (interquartile range, 43-60 years), and 128 (63.7\\%) patients were men. Eighty-four patients (41.8\\%) developed ARDS, and of those 84 patients, 44 (52.4\\%) died. In those who developed ARDS, compared with those who did not, more patients presented with dyspnea (50 of 84 [59.5\\%] patients and 30 of 117 [25.6\\%] patients, respectively [difference, 33.9\\%; 95\\% CI, 19.7\\%-48.1\\%]) and had comorbidities such as hypertension (23 of 84 [27.4\\%] patients and 16 of 117 [13.7\\%] patients, respectively [difference, 13.7\\%; 95\\% CI, 1.3\\%-26.1\\%]) and diabetes (16 of 84 [19.0\\%] patients and 6 of 117 [5.1\\%] patients, respectively [difference, 13.9\\%; 95\\% CI, 3.6\\%-24.2\\%]). In bivariate Cox regression analysis, risk factors associated with the development of ARDS and progression from ARDS to death included older age (hazard ratio [HR], 3.26; 95\\% CI 2.08-5.11; and HR, 6.17; 95\\% CI, 3.26-11.67, respectively), neutrophilia (HR, 1.14; 95\\% CI, 1.09-1.19; and HR, 1.08; 95\\% CI, 1.01-1.17, respectively), and organ and coagulation dysfunction (eg, higher lactate dehydrogenase [HR, 1.61; 95\\% CI, 1.44-1.79; and HR, 1.30; 95\\% CI, 1.11-1.52, respectively] and D-dimer [HR, 1.03; 95\\% CI, 1.01-1.04; and HR, 1.02; 95\\% CI, 1.01-1.04, respectively]). High fever (≥39 °C) was associated with higher likelihood of ARDS development (HR, 1.77; 95\\% CI, 1.11-2.84) and lower likelihood of death (HR, 0.41; 95\\% CI, 0.21-0.82). Among patients with ARDS, treatment with methylprednisolone decreased the risk of death (HR, 0.38; 95\\% CI, 0.20-0.72).Older age was associated with greater risk of development of ARDS and death likely owing to less rigorous immune response. Although high fever was associated with the development of ARDS, it was also associated with better outcomes among patients with ARDS. Moreover, treatment with methylprednisolone may be beneficial for patients who develop ARDS.}",
    issn = {2168-6106},
    doi = {10.1001/jamainternmed.2020.0994},
    url = {https://doi.org/10.1001/jamainternmed.2020.0994},
    eprint = {https://jamanetwork.com/journals/jamainternalmedicine/articlepdf/2763184/jamainternal\_wu\_2020\_oi\_200022.pdf},
}

@article{ARDSML,
  author    = {Tony Wang and
               Tim Tschampel and
               Emilia Apostolova and
               Tom Velez},
  title     = {Using Latent Class Analysis to Identify {ARDS} Sub-phenotypes for
               Enhanced Machine Learning Predictive Performance},
  journal   = {CoRR},
  volume    = {abs/1903.12127},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.12127},
  archivePrefix = {arXiv},
  eprint    = {1903.12127},
  timestamp = {Tue, 02 Apr 2019 11:16:55 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-12127.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{SHAP,
title = {A Unified Approach to Interpreting Model Predictions},
author = {Lundberg, Scott M and Lee, Su-In},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4765--4774},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf}
}

@article{TreeExplainer,
  author    = {Scott M. Lundberg and
               Gabriel G. Erion and
               Hugh Chen and
               Alex DeGrave and
               Jordan M. Prutkin and
               Bala Nair and
               Ronit Katz and
               Jonathan Himmelfarb and
               Nisha Bansal and
               Su{-}In Lee},
  title     = {Explainable {AI} for Trees: From Local Explanations to Global Understanding},
  journal   = {CoRR},
  volume    = {abs/1905.04610},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.04610},
  archivePrefix = {arXiv},
  eprint    = {1905.04610},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-04610.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{TreePerturb,
issn = {0219-1377},
abstract = {We present a sensitivity analysis-based method for explaining prediction models that can be applied to any type of classification or regression model. Its advantage over existing general methods is that all subsets of input features are perturbed, so interactions and redundancies between features are taken into account. Furthermore, when explaining an additive model, the method is equivalent to commonly used additive model-specific methods. We illustrate the method’s usefulness with examples from artificial and real-world data sets and an empirical analysis of running times. Results from a controlled experiment with 122 participants suggest that the method’s explanations improved the participants’ understanding of the model.},
journal = {Knowledge and Information Systems},
pages = {647--665},
volume = {41},
publisher = {Springer London},
number = {3},
year = {2014},
title = {Explaining prediction models and individual predictions with feature contributions},
language = {eng},
address = {London},
author = {Štrumbelj, Erik and Kononenko, Igor},
keywords = {Knowledge discovery ; Data mining ; Visualization ; Interpretability ; Decision support},
}

@article{5000Points,
author = {Goodfellow, I and Bengio, Y and Courville, A},
year = {2016},
title = {Deep Learning},
journal = {MIT Press},
}





@article{APACHE,
author = {Mica, Ladislav and Albrecht, K and Keel, Marius and Trentz, O},
year = {2012},
month = {01},
pages = {},
title = {Independent predictors of early death of polytrauma patients: An analysis of 696 patients},
volume = {1},
journal = {J Trauma Treatment},
doi = {10.5167/uzh-71530}
}

@article{APACHE2,
issn = {1918-3003},
abstract = {BACKGROUNDAcute Physiology, Age and Chronic Health Evaluation (APACHE) II and III scores were developed in 1985 and 1991, respectively, and are used mainly for critically ill patients of all disease categories admitted to the intensive care unit (ICU)....},
journal = {Journal of clinical medicine research},
pages = {907--910},
volume = {9},
number = {11},
year = {2017},
title = {Predicting Mortality of Patients With Sepsis: A Comparison of APACHE II and APACHE III Scoring Systems.},
language = {eng},
author = {Sadaka, Farid and Ethmane Abou El Maali, Cheikh and Cytron, Margaret A and Fowler, Kimberly and Javaux, Victoria M and O'Brien, Jacklyn},
keywords = {Apache ; Acute Physiologic and Chronic Health Evaluation ; Epidemiology ; Mortality ; Outcome ; Sepsis},
url = {http://search.proquest.com/docview/1952104244/},
}

@article{IsAttentionInterpretable,
abstract = {Attention mechanisms have recently boosted performance on a range of NLP tasks. Because attention layers explicitly weight input components' representations, it is also often assumed that attention can be used to identify information that models found important (e.g., specific contextualized word tokens). We test whether that assumption holds by manipulating attention weights in already-trained text classification models and analyzing the resulting differences in their predictions. While we observe some ways in which higher attention weights correlate with greater impact on model predictions, we also find many ways in which this does not hold, i.e., where gradient-based rankings of attention weights better predict their effects than their magnitudes. We conclude that while attention noisily predicts input components' overall importance to a model, it is by no means a fail-safe indicator.},
journal = {arXiv.org},
publisher = {Cornell University Library, arXiv.org},
year = {2019},
title = {Is Attention Interpretable?},
language = {eng},
address = {Ithaca},
author = {Serrano, Sofia and Smith, Noah},
keywords = {Computation and Language},
url = {http://search.proquest.com/docview/2238247948/},
}


